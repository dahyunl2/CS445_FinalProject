{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe==0.10.14 --no-deps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_C1hVx7A3oY",
        "outputId": "a5ed8b4a-d4da-490b-c0a2-327c6171ba89"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mediapipe==0.10.14\n",
            "  Downloading mediapipe-0.10.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
            "Downloading mediapipe-0.10.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mediapipe\n",
            "  Attempting uninstall: mediapipe\n",
            "    Found existing installation: mediapipe 0.10.21\n",
            "    Uninstalling mediapipe-0.10.21:\n",
            "      Successfully uninstalled mediapipe-0.10.21\n",
            "Successfully installed mediapipe-0.10.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import mediapipe as mp\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load overlay image (must be RGBA)\n",
        "cat_overlay = cv2.imread('catEars.png', cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "# Helper: Overlay RGBA with alpha blending\n",
        "def overlay_alpha(img, overlay, x, y):\n",
        "    h, w = overlay.shape[:2]\n",
        "    if x < 0 or y < 0 or x + w > img.shape[1] or y + h > img.shape[0]:\n",
        "        return img  # skip if out of bounds\n",
        "    alpha = overlay[:, :, 3] / 255.0\n",
        "    for c in range(3):\n",
        "        img[y:y + h, x:x + w, c] = (1 - alpha) * img[y:y + h, x:x + w, c] + alpha * overlay[:, :, c]\n",
        "    return img\n",
        "\n",
        "# Improved: rotate image with padding to avoid cropping\n",
        "def rotate_image(image, angle_deg):\n",
        "    (h, w) = image.shape[:2]\n",
        "    center = (w // 2, h // 2)\n",
        "\n",
        "    # Rotation matrix\n",
        "    M = cv2.getRotationMatrix2D(center, angle_deg, 1.0)\n",
        "    cos = np.abs(M[0, 0])\n",
        "    sin = np.abs(M[0, 1])\n",
        "\n",
        "    # New image size\n",
        "    new_w = int((h * sin) + (w * cos))\n",
        "    new_h = int((h * cos) + (w * sin))\n",
        "\n",
        "    # Adjust matrix for translation\n",
        "    M[0, 2] += (new_w / 2) - center[0]\n",
        "    M[1, 2] += (new_h / 2) - center[1]\n",
        "\n",
        "    # Rotate and return\n",
        "    return cv2.warpAffine(image, M, (new_w, new_h), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT, borderValue=(0, 0, 0, 0))\n",
        "\n",
        "# Initialize MediaPipe Face Mesh\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=False, max_num_faces=1)\n",
        "\n",
        "# Load video\n",
        "cap = cv2.VideoCapture('/content/input.mp4')  # Change this path as needed\n",
        "frames = []\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    frames.append(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "cap.release()\n",
        "\n",
        "# Process each frame\n",
        "output_frames = []\n",
        "for frame in frames:\n",
        "    h, w = frame.shape[:2]\n",
        "    result = face_mesh.process(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
        "    if not result.multi_face_landmarks:\n",
        "        output_frames.append(frame)\n",
        "        continue\n",
        "\n",
        "    lm = result.multi_face_landmarks[0].landmark\n",
        "    p1 = np.array([lm[127].x * w, lm[127].y * h])  # left forehead\n",
        "    p2 = np.array([lm[356].x * w, lm[356].y * h])  # right forehead\n",
        "    p_center = np.array([lm[1].x * w, lm[1].y * h])  # nose tip\n",
        "\n",
        "    face_width = np.linalg.norm(p1 - p2)\n",
        "    ear_width = int(face_width * 1.2)\n",
        "    ear_height = int(ear_width * cat_overlay.shape[0] / cat_overlay.shape[1])\n",
        "\n",
        "    # Resize filter to match face width\n",
        "    resized_overlay = cv2.resize(cat_overlay, (ear_width, ear_height), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "    # Compute face tilt angle (in degrees), and flip it!\n",
        "    angle_rad = np.arctan2(p2[1] - p1[1], p2[0] - p1[0])\n",
        "    angle_deg = np.degrees(angle_rad)\n",
        "\n",
        "    # Rotate overlay to match head orientation\n",
        "    rotated_overlay = rotate_image(resized_overlay, -angle_deg)  # ← FIX: negative for correct tilt\n",
        "\n",
        "    # Position: align center x and slightly above nose\n",
        "    top_x = int(p_center[0] - rotated_overlay.shape[1] // 2)\n",
        "    top_y = int(p_center[1] - rotated_overlay.shape[0] * 0.8)  # ← FIX: adjust for nose alignment\n",
        "\n",
        "    out = overlay_alpha(frame.copy(), rotated_overlay, top_x, top_y)\n",
        "    output_frames.append(out)\n",
        "\n",
        "# Save output as MP4\n",
        "bgr_frames = [cv2.cvtColor(f, cv2.COLOR_RGB2BGR) for f in output_frames]\n",
        "height, width = bgr_frames[0].shape[:2]\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter('cat_filter_output.mp4', fourcc, 10.0, (width, height))\n",
        "\n",
        "for frame in bgr_frames:\n",
        "    out.write(frame)\n",
        "out.release()\n",
        "\n",
        "print(\"✅ Saved: cat_filter_output.mp4\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FMHhJ9GHE6i",
        "outputId": "c44a37ee-314e-42a3-db4b-cbd9fa6d40cf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved: cat_filter_output.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ec7g2CcjJCsE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
